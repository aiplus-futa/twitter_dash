{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#function defintions\n",
    "def scrapetweet(search_words, date_since, numTweets):\n",
    "    j_file = json.load(open('twitter_credentials.json', 'r'))\n",
    "    consumer_key = j_file['CONSUMER_KEY']\n",
    "    consumer_secret = j_file['CONSUMER_SECRET']\n",
    "    access_token = j_file['ACCESS_TOKEN']\n",
    "    access_secret = j_file['ACCESS_SECRET']\n",
    "\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    \n",
    "    db_tweets = pd.DataFrame(columns=['username', 'acct_desc', 'location', 'following', 'followers', 'total_tweets', 'user_created', \n",
    "                                     'tweet_created', 'retweet_count', 'text', 'hashtags'])\n",
    "            \n",
    "    tweets = tweepy.Cursor(api.search, q=search_words, lang='en', since=date_since, tweet_mode='extended').items(numTweets)\n",
    "\n",
    "    tweet_list = [tweet for tweet in tweets]\n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        username = tweet.user.screen_name\n",
    "        acctdesc = tweet.user.description\n",
    "        location = tweet.user.location\n",
    "        following = tweet.user.friends_count\n",
    "        followers = tweet.user.followers_count\n",
    "        total_tweets = tweet.user.statuses_count\n",
    "        user_created = tweet.user.created_at\n",
    "        tweet_created = tweet.created_at\n",
    "        retweet_count = tweet.retweet_count\n",
    "        hashtags = tweet.entities['hashtags']\n",
    "\n",
    "        try:\n",
    "            text = tweet.retweeted_status.full_text\n",
    "        except AttributeError:\n",
    "            text = tweet.full_text\n",
    "\n",
    "        ith_tweet = [username, acctdesc, location, following, followers, total_tweets, user_created, tweet_created, retweet_count,\n",
    "                    text, hashtags]\n",
    "\n",
    "        db_tweets.loc[len(db_tweets)] = ith_tweet    \n",
    "    \n",
    "    return db_tweets\n",
    "\n",
    "\n",
    "def clean_hashtag(hashtag):\n",
    "    hashtag = hashtag.replace(\"{'text':\", '')\n",
    "    hashtag = hashtag.replace(\"'indices': [\", '')\n",
    "    hashtag = hashtag.replace(']', '')\n",
    "    hashtag = hashtag.replace('[', '')\n",
    "    hashtag = hashtag.replace('\\'', '')\n",
    "    hashtag = hashtag.replace('}', '')\n",
    "    \n",
    "    \n",
    "    hashtag_list = hashtag.split(',')\n",
    "\n",
    "    for i in range(len(hashtag_list)):\n",
    "        hashtag_list[i] = hashtag_list[i].strip()\n",
    "\n",
    "    for i in hashtag_list:\n",
    "        if str.isdigit(i):\n",
    "            hashtag_list.remove(i)\n",
    "\n",
    "    for i in hashtag_list:\n",
    "        if str.isdigit(i):\n",
    "            hashtag_list.remove(i)\n",
    "\n",
    "    return hashtag_list\n",
    "\n",
    "\n",
    "def remove_https(desc):\n",
    "    text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', desc)\n",
    "    return text\n",
    "\n",
    "def strip_emoji(text):\n",
    "    RE_EMOJI = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])', flags=re.UNICODE)\n",
    "    return RE_EMOJI.sub(r'', text)\n",
    "\n",
    "def clean_data(df):\n",
    "    df.fillna('None', inplace=True)\n",
    "    df['hashtags'] = df['hashtags'].apply(clean_hashtag)\n",
    "    df['acct_desc'] = df['acct_desc'].apply(strip_emoji)\n",
    "    df['acct_desc'] = df['acct_desc'].apply(remove_https)\n",
    "    return df\n",
    "\n",
    "\n",
    "#define the hashtags, starting date and number of tweets to get\n",
    "search_words = \"#70daysofML OR #AIbootcamp2020 OR #DSN70daysofML OR #70daysofDL OR #DSN70daysofDL OR #1_million_AI_talents_in_10_year OR #4-day_scorestreak\"\n",
    "date_since = \"2020-07-01\"\n",
    "numTweets = 300\n",
    "\n",
    "#get new tweets and clean it\n",
    "new_df = scrapetweet(search_words, date_since, numTweets)\n",
    "new_df = clean_data(new_df)\n",
    "\n",
    "#then append it to the previous data\n",
    "df = pd.read_csv('latest.csv')    #replace the path later\n",
    "df.append(new_df, ignore_index=True)\n",
    "\n",
    "#the \"df\" dataframe can now be used for visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
